# ğŸ¤– DevFest RAG Workshop

A complete **Retrieval Augmented Generation (RAG)** workshop project for DevFest 2024. This repository contains both presentation materials and a fully functional RAG implementation with an interactive Streamlit web UI.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [Workshop Materials](#workshop-materials)
- [RAG Implementation](#rag-implementation)
- [Streamlit Web UI](#streamlit-web-ui)
- [Configuration](#configuration)
- [API Reference](#api-reference)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This workshop teaches you how to build a RAG system from scratch. RAG enhances Large Language Models (LLMs) by combining them with external knowledge retrieval, enabling:

- Access to up-to-date information
- Reduced hallucinations
- Domain-specific knowledge integration
- Source attribution and transparency

**What you'll learn:**

- Understanding RAG architecture and components
- Building document loaders and text splitters
- Working with embeddings and vector stores
- Implementing retrieval and generation pipelines
- Creating an interactive web interface

## ğŸ“ Project Structure

```
DevFest-RAG/
â”œâ”€â”€ WHATIS.md                 # Workshop presentation content
â”œâ”€â”€ README.md                 # Project documentation (this file)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ .env.example             # Environment variables template
â”œâ”€â”€ config/
â”‚   â””â”€â”€ default.env          # Default configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_docs/         # Sample documents for demo
â”‚       â”œâ”€â”€ devfest_info.txt
â”‚       â”œâ”€â”€ rag_tutorial.txt
â”‚       â””â”€â”€ python_best_practices.txt
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ rag/                  # Core RAG implementation
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ document_loader.py   # Load documents from files
    â”‚   â”œâ”€â”€ text_splitter.py     # Split text into chunks
    â”‚   â”œâ”€â”€ embeddings.py        # Text to vector embeddings
    â”‚   â”œâ”€â”€ vector_store.py      # Store and query vectors
    â”‚   â”œâ”€â”€ retriever.py         # Retrieve relevant documents
    â”‚   â”œâ”€â”€ generator.py         # Generate responses with LLM
    â”‚   â””â”€â”€ rag_pipeline.py      # Complete RAG pipeline
    â””â”€â”€ ui/
        â”œâ”€â”€ __init__.py
        â””â”€â”€ app.py               # Streamlit web application
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9 or higher
- OpenAI API key (for LLM generation)

### Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/DevFest-RAG.git
   cd DevFest-RAG
   ```

2. **Create a virtual environment:**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**

   ```bash
   cp .env.example .env
   # Edit .env and add your OpenAI API key
   ```

### Quick Start

**Option 1: Run the Streamlit Web UI**

```bash
streamlit run src/ui/app.py
```

**Option 2: Use the Python API**

```python
from src.rag import RAGPipeline

# Initialize the pipeline
pipeline = RAGPipeline(
    embedding_provider="sentence_transformer",
    generator_provider="openai",
    openai_api_key="your-api-key",
)

# Load documents
pipeline.load_documents("data/sample_docs")

# Ask questions
response = pipeline.query("What is RAG?")
print(response.answer)
```

## ğŸ“š Workshop Materials

### Presentation Content

See **[WHATIS.md](WHATIS.md)** for complete workshop presentation content including:

- Definition and description of RAG
- Why RAG is important
- How RAG is used (use cases)
- How RAG works (architecture and components)
- Best practices and tips

## ğŸ”§ RAG Implementation

### Components Overview

| Component | File | Description |
|-----------|------|-------------|
| **Document Loader** | `document_loader.py` | Loads documents from .txt, .md, .pdf files |
| **Text Splitter** | `text_splitter.py` | Splits documents into manageable chunks |
| **Embeddings** | `embeddings.py` | Converts text to vector embeddings |
| **Vector Store** | `vector_store.py` | Stores and queries embeddings using ChromaDB |
| **Retriever** | `retriever.py` | Finds relevant documents for queries |
| **Generator** | `generator.py` | Generates responses using LLMs |
| **RAG Pipeline** | `rag_pipeline.py` | Orchestrates all components |

### Embedding Providers

- **Sentence Transformers** (default, free, local)
  - Model: `all-MiniLM-L6-v2`
  - No API key required
  - Runs locally

- **OpenAI Embeddings** (paid)
  - Model: `text-embedding-3-small`
  - Requires OpenAI API key

### LLM Providers

- **OpenAI** (recommended)
  - Models: `gpt-3.5-turbo`, `gpt-4`
  - Requires API key

- **HuggingFace** (free, local)
  - Model: `google/flan-t5-base`
  - Runs locally (lower quality)

## ğŸ–¥ï¸ Streamlit Web UI

The interactive web UI provides:

- **Configuration Panel**: Set API keys and options
- **Document Management**: Upload files or paste text
- **Query Interface**: Ask questions about your documents
- **Source Display**: View retrieved source documents
- **Chat History**: Track conversation history

### Features

- ğŸ”‘ Secure API key input
- ğŸ“„ Multiple file upload support
- ğŸ“Š Real-time statistics
- ğŸ” Adjustable retrieval parameters
- ğŸ“œ Conversation history
- ğŸ¨ Clean, responsive interface

### Running the UI

```bash
# From project root
streamlit run src/ui/app.py

# The app will open in your browser at http://localhost:8501
```

## âš™ï¸ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key | Required |
| `EMBEDDING_PROVIDER` | Embedding provider | `sentence_transformer` |
| `EMBEDDING_MODEL` | Embedding model name | `all-MiniLM-L6-v2` |
| `GENERATOR_MODEL` | LLM model name | `gpt-3.5-turbo` |
| `CHUNK_SIZE` | Text chunk size | `500` |
| `CHUNK_OVERLAP` | Overlap between chunks | `50` |
| `TOP_K` | Number of documents to retrieve | `5` |

### Configuration Files

- `.env` - Your local environment variables (not committed)
- `.env.example` - Template for environment variables
- `config/default.env` - Default configuration values

## ğŸ“– API Reference

### RAGPipeline

The main class for interacting with the RAG system.

```python
from src.rag import RAGPipeline

# Initialize
pipeline = RAGPipeline(
    embedding_provider="sentence_transformer",
    generator_provider="openai",
    openai_api_key="sk-...",
    chunk_size=500,
    chunk_overlap=50,
    top_k=5,
)

# Load documents from directory
num_chunks = pipeline.load_documents("path/to/docs")

# Add text directly
num_chunks = pipeline.add_text("Your text here", metadata={"source": "manual"})

# Query the system
response = pipeline.query("Your question?")
print(response.answer)
print(response.sources)

# Search without generating
docs = pipeline.search("search query")

# Get statistics
stats = pipeline.get_stats()

# Clear all documents
pipeline.clear()
```

### RAGResponse

Response object returned by `query()`:

```python
@dataclass
class RAGResponse:
    answer: str              # Generated answer
    sources: List[Dict]      # Source documents with scores
    query: str               # Original query
    context_used: str        # Context sent to LLM
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [LangChain](https://python.langchain.com/) - Inspiration for RAG architecture
- [ChromaDB](https://docs.trychroma.com/) - Vector database
- [Streamlit](https://streamlit.io/) - Web UI framework
- [Sentence Transformers](https://www.sbert.net/) - Free embedding models
- [OpenAI](https://openai.com/) - LLM provider

---

**Happy Learning! ğŸ‰**

*Built with â¤ï¸ for DevFest 2024*
